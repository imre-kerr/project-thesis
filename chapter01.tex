% !TEX encoding = UTF-8 Unicode
%!TEX root = thesis.tex
% !TEX spellcheck = en-US
%%=========================================
\chapter{Introduction}

%%=========================================
\section{Background}
\subsection{Graphics Hardware}
Graphics processing units (GPUs) are special-purpose processors designed with graphics in mind. Computer graphics require large amounts of calculations, typically the same calculations done over and over. This type of workload is very different from the mostly serial workloads typically done by CPUs. Hence, large performance benefits can be gotten by using specialized hardware with a large number of execution units in a single-instruction/multiple-data (SIMD) setup.

%%=========================================
\subsection{General-Purpose GPU Computing}
As it happens, there is another field where SIMD hardware is widely used: scientific computing. A typical physics simulation (e.g. a weather report) can involve solving systems of equations with thousands of unknowns. Historically, vector processors were used for this purpose. However, these processors were little used outside of scientific computing, leading to high cost due to the nature of semiconductor manufacturing. Designing a processor, making photolithography masks and buying fabrication equipment are all extremely expensive. Once these are done, though, processors can be made at next to no cost, leading to economies of scale. 

GPUs, on the other hand, are sold in vast quantities to the consumer market, due in no small part to computer games. If one could use graphics hardware to compute other things than graphics, one could potentially do scientific computing at much lower cost.

Experiments in general-purpose GPU (GPGPU for short) computing began with \citet{larsen2001fast}, which presents a routine for matrix multiplication using graphics hardware. This was enabled by graphics hardware that supported programmable shaders and floating-point arithmetic, which had previously been lacking. \citet{galoppo2005lu} represented one of the first implementations of a common scientific programming primitive which ran faster than the CPU implementation.

However, GPGPU still had one fatal flaw. The only APIs available for interfacing with GPUs were graphics APIs, in particular OpenGL and DirectX. Programming for GPUs therefore meant casting everything in terms of graphics primitives, which was tedious, error-prone and inaccessible.

%%=========================================
\subsection{CUDA}
Released in 2006, Nvidia's CUDA sought to make GPU programming easier by letting programmers write programs as they were used to, namely in terms of the task at hand rather than graphics primitives. CUDA is currently widely used, not only in scientific computing, but also for image and video processing, cryptography, physics simulation in games and more.

The CUDA programming model splits code into host-side code, which runs on the CPU, and device-side code (also called kernels) which runs on the GPU. When calling a kernel, the number of threads to be created is included as an argument. Copying data between the host and device, as well as allocating memory on the device, is done explicitly. This allows the programmer to take advantage of the memory hierarchy on the device, placing often-used data in fast memory.

A much more thorough treatment of the CUDA programming model is given in the CUDA C Programming guide \citep{nvidia2014programming}.

%%=========================================
\subsection{OpenCL}
While CUDA has enjoyed great popularity, it suffers from vendor lock-in due to the fact that it only supports Nvidia GPUs. In an effort to create an open standard for GPU computing (or more precisely, heterogeneous computing), OpenCL was created. Originally developed by Apple, it is currently maintained by the Khronos Group.

While CUDA and OpenCL have many similarities, there are a few key differences to note:
\begin{itemize}
\item CUDA is a \emph{GPU programming} API, while OpenCL is a \emph{heterogeneous programming} API. OpenCL implementations exist not only for GPUs, but also CPUs, APUs, and more exotic hardware such as Adapteva's Epiphany processor.
\item To maintain compatibility across platforms, OpenCL device-side code must be compiled at runtime. This incurs a penalty in startup time compared to CUDA.
\end{itemize}
Finally, although OpenCL code is portable, code which has good performance on one platform is not necessarily performant on others. This issue of code portability versus performance portability, as well as the relative performance of OpenCL versus CUDA in general, is treated by \citet{weber2011comparing}.

%%=========================================
\section{Goals}
The main goal for this project can be stated simply as “Port the HPC-Lab Snow Simulator to OpenCL”. However, there are a few secondary goals that should be considered as well.

Firstly, this is not the first time the snow simulator has been ported to OpenCL. The previous port was obsolete pretty much out of the gate, which is why the most current version has always been CUDA only. I can see two possible reasons for this. One is simply that working with two APIs is more work than working with one, and people are likely to just take the path of least resistance. To mitigate this, an OpenCL port should have the API specific code isolated from the rest of the code, separated by a clean abstraction layer. This will ensure that making changes to the host-side code will be just as easy in the cross-platform version as in the CUDA only version. One should also take steps to make the OpenCL and CUDA code both as readable and as similar to each other as possible. This will minimize the work required to make changes to the device-side code, and hopefully encourage people to keep both versions of this code up to date.

Additionally, other students are also doing projects involving the snow simulator this semester. If their work and mine are not kept in sync with frequent merging, we might end up with separate versions, and future projects will need to choose between these when choosing what code base to work on.

Finally, the snow simulator is a very computationally intensive program. Producing correct code should of course be priority number one, but one should not neglect performance. Therefore I will analyze the performance of the simulator using whatever tools I can, and explore options for using OpenCL-specific tricks to improve this performance.

%%=========================================
\section{Motivation}
Rather than being a purely academic exercise, there are a few reasons why an OpenCL port of the Snow Simulator was desired. Of course, supporting more platforms is ``better'', but we had a few things in mind apart from this.

First of all, it paves the way for exploring GPGPU on mobile platforms. Even though Nvidia's Tegra chips got CUDA support with the Tegra K1, only a few devices with this processor are currently available. An OpenCL version will enable us to use mobile graphics hardware such as e.g. ARM's Mali GPU.

Also, when this project was started, there were plans for the HPC Lab to build a display wall. Such a display is composed of several smaller screens, allowing for large screen size and resolution at a moderate price. We found that the best choice for a large multi-monitor setup like this would be AMD's Eyefinity. Running the Snow Simulator on AMD hardware would require an OpenCL port. This project may still happen at some point, but it is less of a priority since the Lab recently purchased an 85-inch 4k monitor, which fills the same role.

%%=========================================
\section{Structure of the Report}
The rest of the report is organized as follows. Chapter 2 describes the actual porting work (briefly, as this is quite boring and mechanical), before going into the testing that was done, as well as the results of these tests. Chapter 3 discusses the results, suggests future work based on these.